#!/usr/bin/env python3
"""
ì „ì²´ personì— ëŒ€í•œ ë™ì¼ì¸ë¬¼ ê±°ë¦¬ + ë‹¨ì²´ì‚¬ì§„ ê²°ê³¼ + ì •ë°€ë„/ì¬í˜„ìœ¨ í†µí•© ë¶„ì„
"""
import pandas as pd
from pathlib import Path
import numpy as np
import json

def load_same_person_distances():
    """threshold_tuning ê²°ê³¼ì—ì„œ ë™ì¼ì¸ë¬¼ ê°„ ê±°ë¦¬ ë¡œë“œ"""
    output_dir = Path('data/output')
    results = {}
    
    for person_dir in sorted(output_dir.glob('threshold_tuning_person*')):
        person_name = person_dir.name.replace('threshold_tuning_', '')
        
        # ê°€ì¥ ìµœê·¼ results CSV íŒŒì¼ ì°¾ê¸°
        csv_files = list(person_dir.glob('results_*.csv'))
        if csv_files:
            latest_csv = sorted(csv_files)[-1]
            df = pd.read_csv(latest_csv)
            
            # ë™ì¼ì¸ë¬¼ í‰ê·  ê±°ë¦¬ì™€ í‘œì¤€í¸ì°¨
            same_avg = df['same_person_avg_dist'].iloc[0]
            same_std = df['same_person_std'].iloc[0]
            
            results[person_name] = {
                'same_avg': same_avg,
                'same_std': same_std
            }
    
    return results

def load_group_results():
    """threshold_tuning_group ê²°ê³¼ì—ì„œ ë‹¨ì²´ì‚¬ì§„ ë¶„ì„ ë¡œë“œ"""
    output_dir = Path('data/output')
    results = {}
    
    for person_dir in sorted(output_dir.glob('threshold_tuning_group_person*')):
        person_name = person_dir.name.replace('threshold_tuning_group_', '')
        
        # summary.csv ë¡œë“œ
        summary_file = person_dir / 'summary.csv'
        if summary_file.exists():
            df = pd.read_csv(summary_file)
            
            # threshold 0.45 ê²°ê³¼ ì°¾ê¸°
            th_045 = df[df['threshold'] == 0.45]
            if len(th_045) > 0:
                row = th_045.iloc[0]
                results[person_name] = {
                    'threshold': 0.45,
                    'total_faces': int(row['total_faces']),
                    'same_person_count': int(row['same_person_count']),
                    'min_distance': float(row['min_distance']),
                    'detected': int(row['same_person_count']) > 0
                }
    
    return results

def calculate_precision_recall(all_results, threshold=0.45):
    """
    ì •ë°€ë„/ì¬í˜„ìœ¨ ê³„ì‚°
    
    TP (True Positive): ê¸°ì¤€ì¸ë¬¼ì„ ê¸°ì¤€ì¸ë¬¼ë¡œ ì¸ì‹ (same_person_count > 0)
    FP (False Positive): íƒ€ì¸ì„ ê¸°ì¤€ì¸ë¬¼ë¡œ ì¸ì‹ (ë§¤ìš° ë“œë¬¼ì§€ë§Œ ë°œìƒ ê°€ëŠ¥)
    FN (False Negative): ê¸°ì¤€ì¸ë¬¼ì„ ë†“ì¹¨ (same_person_count = 0)
    TN (True Negative): íƒ€ì¸ì„ íƒ€ì¸ìœ¼ë¡œ ì¸ì‹ (ì •í™•íˆ ì¸¡ì •í•˜ë ¤ë©´ ëª¨ë“  ì–¼êµ´ ê²€ì¦ í•„ìš”)
    
    ë‹¨ì²´ì‚¬ì§„ ì‹¤í—˜ì—ì„œ:
    - TP: ê¸°ì¤€ì¸ë¬¼ íƒì§€ ì„±ê³µ (same_person_count > 0)
    - FN: ê¸°ì¤€ì¸ë¬¼ íƒì§€ ì‹¤íŒ¨ (same_person_count = 0)
    - FP: íƒ€ì¸ì„ ê¸°ì¤€ì¸ë¬¼ë¡œ ì˜¤ì¸ (total_faces - same_person_count ì¤‘ ì‹¤ì œ íƒ€ì¸ì´ ë³´ì¡´ëœ ê²½ìš°)
    
    ì •ë°€ë„ = TP / (TP + FP) â‰ˆ íƒì§€ëœ ì–¼êµ´ ì¤‘ ì§„ì§œ ë³¸ì¸ ë¹„ìœ¨
    ì¬í˜„ìœ¨ = TP / (TP + FN) = ì „ì²´ ê¸°ì¤€ì¸ë¬¼ ì¤‘ íƒì§€ ì„±ê³µ ë¹„ìœ¨
    """
    
    tp = 0  # ê¸°ì¤€ì¸ë¬¼ íƒì§€ ì„±ê³µ
    fn = 0  # ê¸°ì¤€ì¸ë¬¼ íƒì§€ ì‹¤íŒ¨
    fp_estimate = 0  # íƒ€ì¸ ì˜¤ì¸ (ì¶”ì •)
    
    detected_persons = []
    failed_persons = []
    
    for person, data in all_results.items():
        if 'detected' in data:
            if data['detected']:
                tp += 1
                detected_persons.append(person)
                
                # FP ì¶”ì •: same_person_countê°€ 2 ì´ìƒì´ë©´ íƒ€ì¸ ì˜¤ì¸ ê°€ëŠ¥ì„±
                # (ë‹¨, ì‹¤ì œë¡œëŠ” ê°ë„ê°€ ë‹¤ë¥¸ ê°™ì€ ì‚¬ëŒì¼ ìˆ˜ë„ ìˆìŒ)
                if data['same_person_count'] > 1:
                    fp_estimate += (data['same_person_count'] - 1)
            else:
                fn += 1
                failed_persons.append(person)
    
    # ì •ë°€ë„: ë³´ì¡´í•œ ì–¼êµ´ ì¤‘ ì‹¤ì œ ë³¸ì¸ ë¹„ìœ¨ (FPê°€ ê±°ì˜ ì—†ë‹¤ê³  ê°€ì •í•˜ë©´ ë†’ìŒ)
    precision = tp / (tp + fp_estimate) if (tp + fp_estimate) > 0 else 0
    
    # ì¬í˜„ìœ¨: ì „ì²´ ë³¸ì¸ ì¤‘ ì°¾ì€ ë¹„ìœ¨
    recall = tp / (tp + fn) if (tp + fn) > 0 else 0
    
    # F1 Score
    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0
    
    return {
        'tp': tp,
        'fn': fn,
        'fp_estimate': fp_estimate,
        'precision': precision,
        'recall': recall,
        'f1_score': f1_score,
        'detected_persons': detected_persons,
        'failed_persons': failed_persons
    }

def main():
    print("=" * 80)
    print("ì „ì²´ Person í†µí•© ë¶„ì„: ë™ì¼ì¸ë¬¼ ê±°ë¦¬ + ë‹¨ì²´ì‚¬ì§„ ê²°ê³¼ + ì •ë°€ë„/ì¬í˜„ìœ¨")
    print("=" * 80)
    print()
    
    # 1. ë™ì¼ì¸ë¬¼ ê±°ë¦¬ ë¡œë“œ
    print("ğŸ“Š ë™ì¼ì¸ë¬¼ ê°„ ê±°ë¦¬ ë¶„ì„ ë¡œë“œ ì¤‘...")
    same_distances = load_same_person_distances()
    print(f"   ë¡œë“œ ì™„ë£Œ: {len(same_distances)}ëª…")
    print()
    
    # 2. ë‹¨ì²´ì‚¬ì§„ ê²°ê³¼ ë¡œë“œ
    print("ğŸ“¸ ë‹¨ì²´ì‚¬ì§„ ë¶„ì„ ê²°ê³¼ ë¡œë“œ ì¤‘...")
    group_results = load_group_results()
    print(f"   ë¡œë“œ ì™„ë£Œ: {len(group_results)}ëª…")
    print()
    
    # 3. ë°ì´í„° í†µí•©
    all_results = {}
    for person in sorted(set(same_distances.keys()) | set(group_results.keys())):
        all_results[person] = {}
        
        if person in same_distances:
            all_results[person].update(same_distances[person])
        
        if person in group_results:
            all_results[person].update(group_results[person])
    
    print("=" * 80)
    print(f"í†µí•© ë¶„ì„ ê²°ê³¼ (ì´ {len(all_results)}ëª…, Threshold = 0.45)")
    print("=" * 80)
    print()
    print(f"{'Person':<12} {'ë™ì¼ì¸ë¬¼ í‰ê· ':>12} {'ë™ì¼ì¸ë¬¼ std':>12} {'ê·¸ë£¹ ìµœì†Œê±°ë¦¬':>12} "
          f"{'íƒì§€ ì–¼êµ´ìˆ˜':>10} {'ì „ì²´ ì–¼êµ´':>10} {'íƒì§€ ì„±ê³µ':>10}")
    print("-" * 80)
    
    # í†µê³„ ìˆ˜ì§‘
    same_avgs = []
    group_mins = []
    success_count = 0
    fail_count = 0
    
    for person, data in all_results.items():
        same_avg = data.get('same_avg', 0)
        same_std = data.get('same_std', 0)
        group_min = data.get('min_distance', 0)
        same_count = data.get('same_person_count', 0)
        total_faces = data.get('total_faces', 0)
        detected = data.get('detected', False)
        
        if same_avg > 0:
            same_avgs.append(same_avg)
        if group_min > 0:
            group_mins.append(group_min)
        
        if detected:
            success_count += 1
            status = "âœ… ì„±ê³µ"
        else:
            fail_count += 1
            status = "âŒ ì‹¤íŒ¨"
        
        print(f"{person:<12} {same_avg:>12.4f} {same_std:>12.4f} {group_min:>12.4f} "
              f"{same_count:>10} {total_faces:>10} {status:>10}")
    
    print("=" * 80)
    print()
    
    # 4. í†µê³„ ìš”ì•½
    print("ğŸ“ˆ í†µê³„ ìš”ì•½")
    print("=" * 80)
    print()
    
    print("ğŸ”¹ ë™ì¼ì¸ë¬¼ ê°„ ê±°ë¦¬ (ë ˆí¼ëŸ°ìŠ¤ 3ì¥ ì¡°í•©)")
    if same_avgs:
        print(f"   í‰ê· : {np.mean(same_avgs):.4f}")
        print(f"   ì¤‘ì•™ê°’: {np.median(same_avgs):.4f}")
        print(f"   í‘œì¤€í¸ì°¨: {np.std(same_avgs):.4f}")
        print(f"   ìµœì†Œ: {np.min(same_avgs):.4f}")
        print(f"   ìµœëŒ€: {np.max(same_avgs):.4f}")
    print()
    
    print("ğŸ”¹ ë‹¨ì²´ì‚¬ì§„ ìµœì†Œ ê±°ë¦¬ (ë ˆí¼ëŸ°ìŠ¤ì™€ ê°€ì¥ ê°€ê¹Œìš´ ì–¼êµ´)")
    if group_mins:
        print(f"   í‰ê· : {np.mean(group_mins):.4f}")
        print(f"   ì¤‘ì•™ê°’: {np.median(group_mins):.4f}")
        print(f"   í‘œì¤€í¸ì°¨: {np.std(group_mins):.4f}")
        print(f"   ìµœì†Œ: {np.min(group_mins):.4f}")
        print(f"   ìµœëŒ€: {np.max(group_mins):.4f}")
    print()
    
    print("ğŸ”¹ Threshold 0.45 ì„±ëŠ¥")
    total = success_count + fail_count
    print(f"   íƒì§€ ì„±ê³µ: {success_count}ëª… ({success_count/total*100:.1f}%)")
    print(f"   íƒì§€ ì‹¤íŒ¨: {fail_count}ëª… ({fail_count/total*100:.1f}%)")
    print()
    
    # 5. ì •ë°€ë„/ì¬í˜„ìœ¨ ê³„ì‚°
    print("=" * 80)
    print("ğŸ¯ ì •ë°€ë„/ì¬í˜„ìœ¨ ë¶„ì„ (Threshold = 0.45)")
    print("=" * 80)
    print()
    
    metrics = calculate_precision_recall(all_results, threshold=0.45)
    
    print("ğŸ“Š í˜¼ë™ í–‰ë ¬ (Confusion Matrix)")
    print(f"   TP (True Positive - ê¸°ì¤€ì¸ë¬¼ íƒì§€ ì„±ê³µ): {metrics['tp']}ëª…")
    print(f"   FN (False Negative - ê¸°ì¤€ì¸ë¬¼ íƒì§€ ì‹¤íŒ¨): {metrics['fn']}ëª…")
    print(f"   FP (False Positive - íƒ€ì¸ ì˜¤ì¸ ì¶”ì •): {metrics['fp_estimate']}ê±´")
    print()
    
    print("ğŸ“ˆ ì„±ëŠ¥ ì§€í‘œ")
    print(f"   ì •ë°€ë„ (Precision): {metrics['precision']:.2%}")
    print(f"      â†’ ë³´ì¡´í•œ ì–¼êµ´ ì¤‘ ì‹¤ì œ ë³¸ì¸ ë¹„ìœ¨")
    print(f"   ì¬í˜„ìœ¨ (Recall): {metrics['recall']:.2%}")
    print(f"      â†’ ì „ì²´ ë³¸ì¸ ì¤‘ ì°¾ì€ ë¹„ìœ¨")
    print(f"   F1 Score: {metrics['f1_score']:.2%}")
    print(f"      â†’ ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™” í‰ê· ")
    print()
    
    print("âœ… íƒì§€ ì„±ê³µ ëª©ë¡:")
    for i, person in enumerate(metrics['detected_persons'], 1):
        print(f"   {i}. {person}")
    print()
    
    print("âŒ íƒì§€ ì‹¤íŒ¨ ëª©ë¡:")
    for i, person in enumerate(metrics['failed_persons'], 1):
        print(f"   {i}. {person}")
    print()
    
    # 6. CSV/JSON ì €ì¥
    output_dir = Path('data/output')
    
    # CSV ì €ì¥
    df = pd.DataFrame([
        {
            'person': person,
            'same_person_avg_distance': data.get('same_avg', 0),
            'same_person_std': data.get('same_std', 0),
            'group_min_distance': data.get('min_distance', 0),
            'detected_faces_count': data.get('same_person_count', 0),
            'total_faces': data.get('total_faces', 0),
            'detected_success': data.get('detected', False)
        }
        for person, data in all_results.items()
    ])
    csv_path = output_dir / 'precision_recall_analysis.csv'
    df.to_csv(csv_path, index=False)
    print(f"ğŸ’¾ CSV ì €ì¥: {csv_path}")
    
    # JSON ì €ì¥ (í†µê³„ í¬í•¨)
    summary = {
        'threshold': 0.45,
        'total_persons': len(all_results),
        'statistics': {
            'same_person_distance': {
                'mean': float(np.mean(same_avgs)) if same_avgs else 0,
                'median': float(np.median(same_avgs)) if same_avgs else 0,
                'std': float(np.std(same_avgs)) if same_avgs else 0,
                'min': float(np.min(same_avgs)) if same_avgs else 0,
                'max': float(np.max(same_avgs)) if same_avgs else 0
            },
            'group_min_distance': {
                'mean': float(np.mean(group_mins)) if group_mins else 0,
                'median': float(np.median(group_mins)) if group_mins else 0,
                'std': float(np.std(group_mins)) if group_mins else 0,
                'min': float(np.min(group_mins)) if group_mins else 0,
                'max': float(np.max(group_mins)) if group_mins else 0
            }
        },
        'performance': {
            'detection_success': success_count,
            'detection_failure': fail_count,
            'success_rate': success_count / total if total > 0 else 0
        },
        'precision_recall': {
            'true_positive': metrics['tp'],
            'false_negative': metrics['fn'],
            'false_positive_estimate': metrics['fp_estimate'],
            'precision': metrics['precision'],
            'recall': metrics['recall'],
            'f1_score': metrics['f1_score']
        },
        'detected_persons': metrics['detected_persons'],
        'failed_persons': metrics['failed_persons']
    }
    
    json_path = output_dir / 'precision_recall_analysis.json'
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    print(f"ğŸ’¾ JSON ì €ì¥: {json_path}")
    print()
    
    print("=" * 80)
    print("âœ… ë¶„ì„ ì™„ë£Œ!")
    print("=" * 80)

if __name__ == "__main__":
    main()
